{
    "docs": [
        {
            "location": "/",
            "text": "What is Plasmid Extractor?\n\n\nPlasmid Extractor is a command-line pipeline to search raw reads for plasmids and reconstruct the sequences of any plasmids found. To do this, it uses a fully customizable database of \nover 9000\n plasmid\nsequences from RefSeq, enabling plasmid finding with higher sensitivity and specificity than other published tools.\n\n\nHow Does Plasmid Extractor Work?\n\n\nADD A PICTURE HERE ONCE PIPELINE WORKFLOWS ARE FINALIZED\n\n\nFirst, PlasmidExtractor looks at the input directory specified by the user to find paired reads and generates a list of samples. For each sample found, the following workflow is followed:\n\n\n\n\nQuality trim reads using BBDuk. \n\n\nBait out reads from the trimmed read set that have matches to the plasmid database, again using BBDuk.\n\n\nPerform a preliminary screen for plasmid content using Mash.\n\n\nFor each potential plasmid found from the Mash screen, find out exactly how well it's represented by splitting the plasmid reads generated in step 2 and the plasmid sequence itself into 31-mers and finding what proportion of plasmid sequence 31-mers are covered by plasmid read 31-mers.\n\n\nFilter out confirmed plasmid hits that have a high degree of similarity to one another, as the database may contain extremely similar plasmids. This step also faciliates the creation of custom databases, \nas it means that when adding new plasmids to the database it isn't necessary to check if that plasmid is already represented. In each group of similar plasmids, the plasmid hit with the highest score (proportion of plasmid sequence kmers that are covered by read kmers) is taken as a definitive hit.\n\n\nA consensus sequence is created for each definitive hit is generated by mapping plasmid reads to reference sequences using BBMap, .\n\n\n\n\nOnce these 6 steps have been followed for each sample, the following post-analysis steps are taken:\n\n\n\n\nCompare total plasmid content across samples using sourmash.\n\n\nIdentify AMR genes present on plasmid sequences using BLAST and ??? database.\n\n\nIdentify plasmid incompatibility group for each plasmid using BLAST and ??? database.\n\n\nIdentify pathogenicity genes present on each plasmid using BLAST and ??? database.\n\n\n\n\nIMPORTANT NOTE: While AMR, incompatibility group, and pathogenicity gene detection have been implemented,\nthey have not been thoroughly tested. At this point, if you are interested in these features, it is recommended you do a search\nof your own.",
            "title": "Home"
        },
        {
            "location": "/#what-is-plasmid-extractor",
            "text": "Plasmid Extractor is a command-line pipeline to search raw reads for plasmids and reconstruct the sequences of any plasmids found. To do this, it uses a fully customizable database of  over 9000  plasmid\nsequences from RefSeq, enabling plasmid finding with higher sensitivity and specificity than other published tools.",
            "title": "What is Plasmid Extractor?"
        },
        {
            "location": "/#how-does-plasmid-extractor-work",
            "text": "ADD A PICTURE HERE ONCE PIPELINE WORKFLOWS ARE FINALIZED  First, PlasmidExtractor looks at the input directory specified by the user to find paired reads and generates a list of samples. For each sample found, the following workflow is followed:   Quality trim reads using BBDuk.   Bait out reads from the trimmed read set that have matches to the plasmid database, again using BBDuk.  Perform a preliminary screen for plasmid content using Mash.  For each potential plasmid found from the Mash screen, find out exactly how well it's represented by splitting the plasmid reads generated in step 2 and the plasmid sequence itself into 31-mers and finding what proportion of plasmid sequence 31-mers are covered by plasmid read 31-mers.  Filter out confirmed plasmid hits that have a high degree of similarity to one another, as the database may contain extremely similar plasmids. This step also faciliates the creation of custom databases, \nas it means that when adding new plasmids to the database it isn't necessary to check if that plasmid is already represented. In each group of similar plasmids, the plasmid hit with the highest score (proportion of plasmid sequence kmers that are covered by read kmers) is taken as a definitive hit.  A consensus sequence is created for each definitive hit is generated by mapping plasmid reads to reference sequences using BBMap, .   Once these 6 steps have been followed for each sample, the following post-analysis steps are taken:   Compare total plasmid content across samples using sourmash.  Identify AMR genes present on plasmid sequences using BLAST and ??? database.  Identify plasmid incompatibility group for each plasmid using BLAST and ??? database.  Identify pathogenicity genes present on each plasmid using BLAST and ??? database.   IMPORTANT NOTE: While AMR, incompatibility group, and pathogenicity gene detection have been implemented,\nthey have not been thoroughly tested. At this point, if you are interested in these features, it is recommended you do a search\nof your own.",
            "title": "How Does Plasmid Extractor Work?"
        },
        {
            "location": "/installation/",
            "text": "System Requirements\n\n\nPlasmidExtractor has been developed and tested on Linux-based systems (more specifically Ubuntu and Mint). Any Linux/Unix-based system (including MacOS) should be able to run the pipeline, while users of Windows-based systems will have to use Docker in order to have the pipeline run.\n\n\nIn terms of system specs the more CPUs your system has, the better, as almost every step of the pipeline is multi-threaded. RAM requirements can be somewhat heavy, with some parts of the pipeline more than 20 GB due to the size of the database that PlasmidExtractor uses. 32 GB or RAM is recommended. If your machine does not meet these requirements, PlasmidExtractor can be run in a low-memory mode, where memory usage should peak at ~7GB, enabling the pipeline to run on a much wider range of machines.\n\n\nInstallation Using Docker\n\n\nComing soon...\n\n\nInstalling Using Pip\n\n\nExecutable\n\n\nPlasmidExtractor can also be installed using pip. Use of a virtual environment for PlasmidExtractor is highly recommended. To create a virtualenv:\n\n\n\n\nCreate an empty directory (i.e. \nmkdir ~/Virtual_Environments/PlasmidExtractor\n)\n\n\nVirtualenv that directory (\nvirtualenv -p /usr/bin/python3 ~/Virtual_Environments/PlasmidExtractor\n)\n\n\nActivate the virtualenv (\nsource ~/Virtual_Environments/PlasmidExtractor/bin/activate\n)\n\n\nInstall PlasmidExtractor - this should also install any python packages necessary for PlasmidExtractor to run. (\npip install plasmidextractor\n)\n\n\n\n\nWith this done, you'll need to make sure that any necessary dependencies are installed.\n\n\nDependencies\n\n\nWith that done, you will need to make sure that you have all of the depedencies for PlasmidExtractor installed and present on your $PATH. The dependencies for PlasmidExtractor are:\n\n\n\n\nsamtools >= 1.6\n\n\nbcftools >= 1.6\n\n\nncbi-blast >= 2.2.31\n\n\nbedtools >= 2.25.0\n\n\nBBtools >= 37.23\n\n\nmash >= 2.0\n\n\nkmc >= 3.0\n\n\npython >= 3.5\n\n\n\n\nFor instructions on how to add programs to your $PATH, click \nhere\n.\n\n\nIf all of your dependencies are properly installed, you should now be able to run PlasmidExtractor. If installation of a dependency has not worked, you should get a \nModuleNotFoundError\n for the depedency that has not been able to run properly.\n\n\nFor visualization of sourmash results, you may need to install the python3-tk library. On a debian-based system, you can do this with: \napt-get install python3-tk\n\n\nDatabases\n\n\nOnce you have the executable and dependencies installed, you'll just need to download the databases that ConFindr depends on.\n\n\nThe databases necessary for PlasmidExtractor are hosted on FigShare.\n\n\nTo download them, use the following command in the folder you want to download the databases to:\n\n\nwget https://ndownloader.figshare.com/files/9827323  && tar xf 9827323\n\n\nThis will create a folder in you current working directory called databases.",
            "title": "Installation"
        },
        {
            "location": "/installation/#system-requirements",
            "text": "PlasmidExtractor has been developed and tested on Linux-based systems (more specifically Ubuntu and Mint). Any Linux/Unix-based system (including MacOS) should be able to run the pipeline, while users of Windows-based systems will have to use Docker in order to have the pipeline run.  In terms of system specs the more CPUs your system has, the better, as almost every step of the pipeline is multi-threaded. RAM requirements can be somewhat heavy, with some parts of the pipeline more than 20 GB due to the size of the database that PlasmidExtractor uses. 32 GB or RAM is recommended. If your machine does not meet these requirements, PlasmidExtractor can be run in a low-memory mode, where memory usage should peak at ~7GB, enabling the pipeline to run on a much wider range of machines.",
            "title": "System Requirements"
        },
        {
            "location": "/installation/#installation-using-docker",
            "text": "Coming soon...",
            "title": "Installation Using Docker"
        },
        {
            "location": "/installation/#installing-using-pip",
            "text": "Executable  PlasmidExtractor can also be installed using pip. Use of a virtual environment for PlasmidExtractor is highly recommended. To create a virtualenv:   Create an empty directory (i.e.  mkdir ~/Virtual_Environments/PlasmidExtractor )  Virtualenv that directory ( virtualenv -p /usr/bin/python3 ~/Virtual_Environments/PlasmidExtractor )  Activate the virtualenv ( source ~/Virtual_Environments/PlasmidExtractor/bin/activate )  Install PlasmidExtractor - this should also install any python packages necessary for PlasmidExtractor to run. ( pip install plasmidextractor )   With this done, you'll need to make sure that any necessary dependencies are installed.  Dependencies  With that done, you will need to make sure that you have all of the depedencies for PlasmidExtractor installed and present on your $PATH. The dependencies for PlasmidExtractor are:   samtools >= 1.6  bcftools >= 1.6  ncbi-blast >= 2.2.31  bedtools >= 2.25.0  BBtools >= 37.23  mash >= 2.0  kmc >= 3.0  python >= 3.5   For instructions on how to add programs to your $PATH, click  here .  If all of your dependencies are properly installed, you should now be able to run PlasmidExtractor. If installation of a dependency has not worked, you should get a  ModuleNotFoundError  for the depedency that has not been able to run properly.  For visualization of sourmash results, you may need to install the python3-tk library. On a debian-based system, you can do this with:  apt-get install python3-tk  Databases  Once you have the executable and dependencies installed, you'll just need to download the databases that ConFindr depends on.  The databases necessary for PlasmidExtractor are hosted on FigShare.  To download them, use the following command in the folder you want to download the databases to:  wget https://ndownloader.figshare.com/files/9827323  && tar xf 9827323  This will create a folder in you current working directory called databases.",
            "title": "Installing Using Pip"
        },
        {
            "location": "/usage/",
            "text": "Usage With a Pip Install\n\n\nThe basic usage of Plasmid Extractor is fairly simple. As input, you will need to provide:\n\n\n\n\na folder containing paired-end reads that you think may have plasmids in them. It is assumed that forward reads contain 'R1' in their name and reverse reads contain 'R2' - see detailed usage for information on how to change this if your reads are named differently. \n\n\na plasmid database (included with the PlasmidExtractor distribution - see \nInstallation\n) \n\n\nresistance/virulence/incompatibility databases (also included with PlasmidExtractor distribution)\n\n\nthe path to a folder where you would like your output to be place (this folder will be created if it does not exist).\n\n\n\n\nFor example, in order to analyze the reads in the directory \n/home/user/reads\n and place the output into \noutput\n using the default plasmid database, the command would be:\n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases\n\n\nWithin the output directory, you will find the following:\n\n\n\n\na CSV file called plasmidReport.csv, which shows the plasmids found for each sample, along with a score that shows (approximately) the percent identity to a reference plasmid\n\n\na folder for each sample, which contains a FASTA file for each plasmid found, a FASTA file with the plasmids concatenated\n\n\nif there was more than one sample, an image file showing a dendrogram of similarity of the total plasmid content of each sample, as well as a heatmap showing similarity\n\n\na log file for each sample showing the output from each step of the pipeline \n\n\nCSV files describing virulence, AMR, and incompatibility genes found for each sample.\n\n\n\n\nUsage with Docker\n\n\nComing soon...\n\n\nA Few Usage Examples\n\n\nThe input parameters of Plasmid Extractor can be customized to your liking. Here are a few examples of different things that could be done:\n\n\n\n\n\n\nSet identity cutoff to 0.8, to increase sensitivity at the cost of specificity.\n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -c 0.8\n\n\n\n\n\n\nKeep around temporary files created during execution to take a look at afterwards.\n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -k\n\n\n\n\n\n\nDon't generate sequences for plasmids found, for speedy analysis.\n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -nc\n\n\n\n\n\n\nRun in low memory mode. \n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -l\n\n\n\n\n\n\nCombine low memory mode with no consensus generation for maximum speed.\n\nExtractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -nc -l\n\n\n\n\n\n\nMandatory Arguments\n\n\n\n\n-o, --output_dir\n: The location for your output folder. Can be anything you want it to. Output folder will be created if it does not exist.\n\n\n-sdb, --sequence_db\n: The path to your sequence database. This database should be an uncompressed multi-fasta file. You can create your own custom database\nof plasmid sequences, or append any plasmid sequences you want to the supplied database.\n\n\n-i, --input_directory\n: The path to your input directory, which contains your paired-end reads to be analyzed. These reads can be uncompressed, or gzip/bzip2 compressed. It is assumed that forward\n reads contain 'R1' and reverse reads contain 'R2'. This assumption can be changed with the \n-fid\n and \n-rid\n options.\n\n\n-d, --databases\n: The path to databases for virulence/AMR/incompatibility gene detection.\n\n\n\n\nOptional Arguments\n\n\n\n\n-t, --threads\n: Number of CPUs to run your analysis on. By default this is the number of cores on your machine. Every step of the pipeline except for consensus sequence generation parallelizes quite well, so it's recommended that this be left at the default unless you need to run other jobs at the same time.\n\n\n-k, --keep_tmpfiles\n: By default, a temporary directory is created in the output folder specified with \n-o\n for each sample and deleted once analysis is complete. Temporary files such as quality-trimmed reads and plasmid-only reads are kept here. Specifying this option will keep these temporary files instead of deleting them, in case you want to inspect intermediate files more closely. \n\n\n-c, --cutoff\n: The score cutoff for a plasmid to be considered present. Corresponds roughly to the percent identity between the generated plasmid and the reference plasmid. By default, set to 0.98 to only allow plasmids to be found that are quite similar. Lower values will generally return more plasmids, with less specificity. \n\n\n-r, --report\n: Name for report that will be created in \n--output_dir\n. Defaults to plasmidReport.csv, but can be changed to whatever you like.\n\n\n-fid, --forward_id\n: Identifier for forward reads. Defaults to \nR1\n, but if your forward reads use a different naming scheme like \n_1\n, specify \n-fid _1\n to have these recognized as forward reads.\n\n\n-rid, --reverse_id\n: Same as \n-fid\n, but for reverse reads.\n\n\n-nc, --no_consensus\n: Finding consensus sequences takes a fair chunk of time. If you want to skip this step and only identify the plasmids present in your sample, add this option. Adding this option means that any post-analysis of your plasmids that would usually take place (AMR detection, etc) will not occur.\n\n\n-l, --low_memory\n: Enabling this flag will make the PlasmidExtractor pipeline use substantially less memory (~7GB of RAM at peak usage instead of >20GB). May cause slight drops in sensitivity, but nothing too drastic. \n\n\n-rp, --remove_plasmid\n: This flag will enable creation of plasmid-free reads, so that you can assemble/do downstream analysis on only chromosomal reads. Cannot be used with the \n-nc\n flag.",
            "title": "Usage"
        },
        {
            "location": "/usage/#usage-with-a-pip-install",
            "text": "The basic usage of Plasmid Extractor is fairly simple. As input, you will need to provide:   a folder containing paired-end reads that you think may have plasmids in them. It is assumed that forward reads contain 'R1' in their name and reverse reads contain 'R2' - see detailed usage for information on how to change this if your reads are named differently.   a plasmid database (included with the PlasmidExtractor distribution - see  Installation )   resistance/virulence/incompatibility databases (also included with PlasmidExtractor distribution)  the path to a folder where you would like your output to be place (this folder will be created if it does not exist).   For example, in order to analyze the reads in the directory  /home/user/reads  and place the output into  output  using the default plasmid database, the command would be: Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases  Within the output directory, you will find the following:   a CSV file called plasmidReport.csv, which shows the plasmids found for each sample, along with a score that shows (approximately) the percent identity to a reference plasmid  a folder for each sample, which contains a FASTA file for each plasmid found, a FASTA file with the plasmids concatenated  if there was more than one sample, an image file showing a dendrogram of similarity of the total plasmid content of each sample, as well as a heatmap showing similarity  a log file for each sample showing the output from each step of the pipeline   CSV files describing virulence, AMR, and incompatibility genes found for each sample.",
            "title": "Usage With a Pip Install"
        },
        {
            "location": "/usage/#usage-with-docker",
            "text": "Coming soon...",
            "title": "Usage with Docker"
        },
        {
            "location": "/usage/#a-few-usage-examples",
            "text": "The input parameters of Plasmid Extractor can be customized to your liking. Here are a few examples of different things that could be done:    Set identity cutoff to 0.8, to increase sensitivity at the cost of specificity. Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -c 0.8    Keep around temporary files created during execution to take a look at afterwards. Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -k    Don't generate sequences for plasmids found, for speedy analysis. Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -nc    Run in low memory mode.  Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -l    Combine low memory mode with no consensus generation for maximum speed. Extractor.py -i /home/user/reads -o output -sdb databases/plasmid_db.fasta -d databases -nc -l    Mandatory Arguments   -o, --output_dir : The location for your output folder. Can be anything you want it to. Output folder will be created if it does not exist.  -sdb, --sequence_db : The path to your sequence database. This database should be an uncompressed multi-fasta file. You can create your own custom database\nof plasmid sequences, or append any plasmid sequences you want to the supplied database.  -i, --input_directory : The path to your input directory, which contains your paired-end reads to be analyzed. These reads can be uncompressed, or gzip/bzip2 compressed. It is assumed that forward\n reads contain 'R1' and reverse reads contain 'R2'. This assumption can be changed with the  -fid  and  -rid  options.  -d, --databases : The path to databases for virulence/AMR/incompatibility gene detection.   Optional Arguments   -t, --threads : Number of CPUs to run your analysis on. By default this is the number of cores on your machine. Every step of the pipeline except for consensus sequence generation parallelizes quite well, so it's recommended that this be left at the default unless you need to run other jobs at the same time.  -k, --keep_tmpfiles : By default, a temporary directory is created in the output folder specified with  -o  for each sample and deleted once analysis is complete. Temporary files such as quality-trimmed reads and plasmid-only reads are kept here. Specifying this option will keep these temporary files instead of deleting them, in case you want to inspect intermediate files more closely.   -c, --cutoff : The score cutoff for a plasmid to be considered present. Corresponds roughly to the percent identity between the generated plasmid and the reference plasmid. By default, set to 0.98 to only allow plasmids to be found that are quite similar. Lower values will generally return more plasmids, with less specificity.   -r, --report : Name for report that will be created in  --output_dir . Defaults to plasmidReport.csv, but can be changed to whatever you like.  -fid, --forward_id : Identifier for forward reads. Defaults to  R1 , but if your forward reads use a different naming scheme like  _1 , specify  -fid _1  to have these recognized as forward reads.  -rid, --reverse_id : Same as  -fid , but for reverse reads.  -nc, --no_consensus : Finding consensus sequences takes a fair chunk of time. If you want to skip this step and only identify the plasmids present in your sample, add this option. Adding this option means that any post-analysis of your plasmids that would usually take place (AMR detection, etc) will not occur.  -l, --low_memory : Enabling this flag will make the PlasmidExtractor pipeline use substantially less memory (~7GB of RAM at peak usage instead of >20GB). May cause slight drops in sensitivity, but nothing too drastic.   -rp, --remove_plasmid : This flag will enable creation of plasmid-free reads, so that you can assemble/do downstream analysis on only chromosomal reads. Cannot be used with the  -nc  flag.",
            "title": "A Few Usage Examples"
        },
        {
            "location": "/customization/",
            "text": "Customizing the Plasmid Database\n\n\nThe plasmid database mentioned in the \nInstallation\n section should be suitable for most purposes, as it contains \nmore than 9000 RefSeq plasmids covering all Bacteria. However, should you wish to add more sequences or use a completely different database,\nthis is entirely possible.\n\n\nAdding on to the Default Database\n\n\nAdding on to the default database is simple. To do so, just append any other sequences you would like PlasmidExtractor to search for to the end of the \nplasmid_db.fasta\n file\nincluded in the database download. This is particularly easily done from the command line. If, for example, you have a new sequence you would like to add to the database called\n\nnew_sequence.fasta\n in the same folder as \nplasmid_db.fasta\n, a simple \ncat\n command can append for you:\n\n\ncat new_sequence.fasta >> plasmid_db.fasta\n \n\n\nUsing A Different Database\n\n\nUsing a different database is also possible and easy to do. A valid plasmid database is any FASTA-formatted (uncompressed) file with one or more sequences within it, with unique names for each.\nTo use a different database, just change the file you're pointing to with the \n-sdb\n option when calling PlasmidExtractor. \n\n\nUsing Custom AMR/Virulence/Incompatibility Group Databases\n\n\nThe defaults databases for AMR/Virulence/Incompatibility Group Detection included with PlasmidExtractor\nare derived from \nCGE Databases\n. Given that there are approximately 8 million different AMR databases out there, it's entirely possible that you have your own favorite that you would like to use. With PlasmidExtractor, you are able to do this with a fairly simple procedure.\n\n\nAdding on to the Defaults\n\n\nIf you want to add on to the default database, you can just add your sequences of interest to the relevant folder, with the caveat that the file extension needs to be \n.tfa\n. So, for example, if you have \na FASTA file with new AMR genes called \namr.fasta\n that you would also like searched, you would move (or copy) the file to \ndatabases/resistance_db\n and rename it to \namr.tfa\n. The following command would do this for you:\n\n\ncp amr.fasta databases/resistance_db/amr.tfa\n\n\nCreating Your Own Database\n\n\nIn the event you don't want anything to do with the included AMR databases, you don't have to use them at all! You can just delete the file in whichever folder you want to use your own databases for, \nand then put the FASTA files for your own database (with the \n.tfa\n extension!) into that folder, and you'll be good to go. Note that the names of the folders for each type of detection must remain the same, and at least one target file must be in each of the folders, or you will have an error.",
            "title": "Customizing Plasmid Extractor"
        },
        {
            "location": "/customization/#customizing-the-plasmid-database",
            "text": "The plasmid database mentioned in the  Installation  section should be suitable for most purposes, as it contains \nmore than 9000 RefSeq plasmids covering all Bacteria. However, should you wish to add more sequences or use a completely different database,\nthis is entirely possible.  Adding on to the Default Database  Adding on to the default database is simple. To do so, just append any other sequences you would like PlasmidExtractor to search for to the end of the  plasmid_db.fasta  file\nincluded in the database download. This is particularly easily done from the command line. If, for example, you have a new sequence you would like to add to the database called new_sequence.fasta  in the same folder as  plasmid_db.fasta , a simple  cat  command can append for you:  cat new_sequence.fasta >> plasmid_db.fasta    Using A Different Database  Using a different database is also possible and easy to do. A valid plasmid database is any FASTA-formatted (uncompressed) file with one or more sequences within it, with unique names for each.\nTo use a different database, just change the file you're pointing to with the  -sdb  option when calling PlasmidExtractor.",
            "title": "Customizing the Plasmid Database"
        },
        {
            "location": "/customization/#using-custom-amrvirulenceincompatibility-group-databases",
            "text": "The defaults databases for AMR/Virulence/Incompatibility Group Detection included with PlasmidExtractor\nare derived from  CGE Databases . Given that there are approximately 8 million different AMR databases out there, it's entirely possible that you have your own favorite that you would like to use. With PlasmidExtractor, you are able to do this with a fairly simple procedure.  Adding on to the Defaults  If you want to add on to the default database, you can just add your sequences of interest to the relevant folder, with the caveat that the file extension needs to be  .tfa . So, for example, if you have \na FASTA file with new AMR genes called  amr.fasta  that you would also like searched, you would move (or copy) the file to  databases/resistance_db  and rename it to  amr.tfa . The following command would do this for you:  cp amr.fasta databases/resistance_db/amr.tfa  Creating Your Own Database  In the event you don't want anything to do with the included AMR databases, you don't have to use them at all! You can just delete the file in whichever folder you want to use your own databases for, \nand then put the FASTA files for your own database (with the  .tfa  extension!) into that folder, and you'll be good to go. Note that the names of the folders for each type of detection must remain the same, and at least one target file must be in each of the folders, or you will have an error.",
            "title": "Using Custom AMR/Virulence/Incompatibility Group Databases"
        },
        {
            "location": "/FAQ/",
            "text": "",
            "title": "FAQ"
        }
    ]
}