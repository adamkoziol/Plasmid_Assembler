{
    "docs": [
        {
            "location": "/",
            "text": "What is Plasmid Extractor?\n\n\nPlasmid Extractor is a command-line pipeline to search raw reads for plasmids and reconstruct the sequences of any plasmids found. To do this, it uses a fully customizable database of \nover 9000\n plasmid\nsequences from RefSeq, enabling plasmid finding with higher sensitivity and specificity than other published tools.\n\n\nHow Does Plasmid Extractor Work?\n\n\nADD A PICTURE HERE ONCE PIPELINE WORKFLOWS ARE FINALIZED\n\n\nFirst, PlasmidExtractor looks at the input directory specified by the user to find paired reads and generates a list of samples. For each sample found, the following workflow is followed:\n\n\n\n\nQuality trim reads using BBDuk. \n\n\nBait out reads from the trimmed read set that have matches to the plasmid database, again using BBDuk.\n\n\nPerform a preliminary screen for plasmid content using Mash.\n\n\nFor each potential plasmid found from the Mash screen, find out exactly how well it's represented by splitting the plasmid reads generated in step 2 and the plasmid sequence itself into 31-mers and finding what proportion of plasmid sequence 31-mers are covered by plasmid read 31-mers.\n\n\nFilter out confirmed plasmid hits that have a high degree of similarity to one another, as the database may contain extremely similar plasmids. This step also faciliates the creation of custom databases, \nas it means that when adding new plasmids to the database it isn't necessary to check if that plasmid is already represented. In each group of similar plasmids, the plasmid hit with the highest score (proportion of plasmid sequence kmers that are covered by read kmers) is taken as a definitive hit.\n\n\nA consensus sequence is created for each definitive hit is generated by mapping plasmid reads to reference sequences using BBMap, .\n\n\n\n\nOnce these 6 steps have been followed for each sample, the following post-analysis steps are taken (steps 2, 3 and 4 to be implemented \nsoon\n):\n\n\n\n\nCompare total plasmid content across samples using sourmash.\n\n\nIdentify AMR genes present on plasmid sequences using BLAST and ??? database.\n\n\nIdentify plasmid incompatibility group for each plasmid using BLAST and ??? database.\n\n\nIdentify pathogenicity genes present on each plasmid using BLAST and ??? database.",
            "title": "Home"
        },
        {
            "location": "/#what-is-plasmid-extractor",
            "text": "Plasmid Extractor is a command-line pipeline to search raw reads for plasmids and reconstruct the sequences of any plasmids found. To do this, it uses a fully customizable database of  over 9000  plasmid\nsequences from RefSeq, enabling plasmid finding with higher sensitivity and specificity than other published tools.",
            "title": "What is Plasmid Extractor?"
        },
        {
            "location": "/#how-does-plasmid-extractor-work",
            "text": "ADD A PICTURE HERE ONCE PIPELINE WORKFLOWS ARE FINALIZED  First, PlasmidExtractor looks at the input directory specified by the user to find paired reads and generates a list of samples. For each sample found, the following workflow is followed:   Quality trim reads using BBDuk.   Bait out reads from the trimmed read set that have matches to the plasmid database, again using BBDuk.  Perform a preliminary screen for plasmid content using Mash.  For each potential plasmid found from the Mash screen, find out exactly how well it's represented by splitting the plasmid reads generated in step 2 and the plasmid sequence itself into 31-mers and finding what proportion of plasmid sequence 31-mers are covered by plasmid read 31-mers.  Filter out confirmed plasmid hits that have a high degree of similarity to one another, as the database may contain extremely similar plasmids. This step also faciliates the creation of custom databases, \nas it means that when adding new plasmids to the database it isn't necessary to check if that plasmid is already represented. In each group of similar plasmids, the plasmid hit with the highest score (proportion of plasmid sequence kmers that are covered by read kmers) is taken as a definitive hit.  A consensus sequence is created for each definitive hit is generated by mapping plasmid reads to reference sequences using BBMap, .   Once these 6 steps have been followed for each sample, the following post-analysis steps are taken (steps 2, 3 and 4 to be implemented  soon ):   Compare total plasmid content across samples using sourmash.  Identify AMR genes present on plasmid sequences using BLAST and ??? database.  Identify plasmid incompatibility group for each plasmid using BLAST and ??? database.  Identify pathogenicity genes present on each plasmid using BLAST and ??? database.",
            "title": "How Does Plasmid Extractor Work?"
        },
        {
            "location": "/installation/",
            "text": "System Requirements\n\n\nPlasmidExtractor has been developed and tested on Linux-based systems (more specifically Ubuntu and Mint). Any Linux/Unix-based system (including MacOS) should be able to run the pipeline, while users of Windows-based systems will have to use Docker in order to have the pipeline run.\n\n\nIn terms of system specs the more CPUs your system has, the better, as almost every step of the pipeline is multi-threaded. RAM requirements can be somewhat heavy, with some parts of the pipeline using up to 20 GB due to the size of the database that PlasmidExtractor uses (a low-memory version of the database is on the to-do list). 32 GB or RAM is recommended, though machines with 24 GB may work.\n\n\nInstallation Using Docker\n\n\nAs PlasmidExtractor has a fair number of dependencies, the easiest way to get it installed and working on your machine is using docker. Instructions on docker installation can be found \nhere\n.\n\n\nOnce you have docker installed, you can load the PlasmidExtractor image by booting a terminal and typing:\n\n\ndocker pull /url/for/PlasmidExtractor/\n.\n\n\nThe pipeline can then be run with: \n\n\ncommand you'll enter once I actually get around to making a docker image\n.\n\n\nInstallation From Source\n\n\nTo install from source, you will first need to clone the GitHub repository. Open a terminal, navigate to where you want to download PlasmidExtractor, and type:\n\n\ngit clone https://github.com/lowandrew/Plasmid_Assembler.git\n\n\nWith that done, you will need to make sure that you have all of the depedencies for PlasmidExtractor installed and present on your $PATH. The dependencies for PlasmidExtractor are:\n\n\n\n\nsamtools >= 1.6\n\n\nbcftools >= 1.6\n\n\nncbi-blast >= 2.2.31\n\n\nbedtools >= 2.25.0\n\n\nBBtools >= 37.23\n\n\nmash >= 2.0\n\n\nkmc >= 3.0\n\n\npython >= 3.5\n\n\n\n\nFor instructions on how to add programs to your $PATH, click \nhere\n.\n\n\nYou will also need to install the python packages that PlasmidExtractor needs to run. The packages need can be found in \nrequirements.txt\n. To install all of them in one go, type:\n\n\npip3 install -r requirements.txt\n\n\nIf all of your dependencies are properly installed, you should now be able to run PlasmidExtractor. If installation of a dependency has not worked, you should get a \nModuleNotFoundError\n for the depedency that has not been able to run properly.",
            "title": "Installation"
        },
        {
            "location": "/installation/#system-requirements",
            "text": "PlasmidExtractor has been developed and tested on Linux-based systems (more specifically Ubuntu and Mint). Any Linux/Unix-based system (including MacOS) should be able to run the pipeline, while users of Windows-based systems will have to use Docker in order to have the pipeline run.  In terms of system specs the more CPUs your system has, the better, as almost every step of the pipeline is multi-threaded. RAM requirements can be somewhat heavy, with some parts of the pipeline using up to 20 GB due to the size of the database that PlasmidExtractor uses (a low-memory version of the database is on the to-do list). 32 GB or RAM is recommended, though machines with 24 GB may work.  Installation Using Docker  As PlasmidExtractor has a fair number of dependencies, the easiest way to get it installed and working on your machine is using docker. Instructions on docker installation can be found  here .  Once you have docker installed, you can load the PlasmidExtractor image by booting a terminal and typing:  docker pull /url/for/PlasmidExtractor/ .  The pipeline can then be run with:   command you'll enter once I actually get around to making a docker image .  Installation From Source  To install from source, you will first need to clone the GitHub repository. Open a terminal, navigate to where you want to download PlasmidExtractor, and type:  git clone https://github.com/lowandrew/Plasmid_Assembler.git  With that done, you will need to make sure that you have all of the depedencies for PlasmidExtractor installed and present on your $PATH. The dependencies for PlasmidExtractor are:   samtools >= 1.6  bcftools >= 1.6  ncbi-blast >= 2.2.31  bedtools >= 2.25.0  BBtools >= 37.23  mash >= 2.0  kmc >= 3.0  python >= 3.5   For instructions on how to add programs to your $PATH, click  here .  You will also need to install the python packages that PlasmidExtractor needs to run. The packages need can be found in  requirements.txt . To install all of them in one go, type:  pip3 install -r requirements.txt  If all of your dependencies are properly installed, you should now be able to run PlasmidExtractor. If installation of a dependency has not worked, you should get a  ModuleNotFoundError  for the depedency that has not been able to run properly.",
            "title": "System Requirements"
        },
        {
            "location": "/usage/",
            "text": "Quickstart\n\n\nThe basic usage of Plasmid Extractor is fairly simple. As input, you will need to provide:\n\n\n\n\na folder containing paired-end reads that you think may have plasmids in them. It is assumed that forward reads contain 'R1' in their name and reverse reads contain 'R2' - see detailed usage for information on how to change this if your reads are named differently. \n\n\na plasmid database (included with the PlasmidExtractor distribution) \n\n\nthe path to a folder where you would like your output to be place (this folder will be created if it does not exist).\n\n\n\n\nFor example, in order to analyze the reads in the directory \n/home/user/reads\n and place the output into \noutput\n using the default plasmid database, the command would be:\n\npython Extractor.py -i /home/user/reads -o output -sdb output\n\n\nWithin the output directory, you will find the following:\n\n\n\n\na CSV file called plasmidReport.csv, which shows the plasmids found for each sample, along with a score that shows (approximately) the percent identity to a reference plasmid\n\n\na folder for each sample, which contains a FASTA file for each plasmid found, a FASTA file with the plasmids concatenated, and the input reads with any plasmid reads discarded\n\n\nif there was more than one sample, an image file showing a dendrogram of similarity of the total plasmid content of each sample, as well as a heatmap showing similarity\n\n\na log file for each sample showing the output from each step of the pipeline \n\n\n\n\nDetailed Usage\n\n\nThe input parameters of Plasmid Extractor can be customized to your liking. Here are a few examples of different things that could be done:\n\n\n\n\n\n\nSet identity cutoff to 0.8, to increase sensitivity at the cost of specificity.\n\npython Extractor.py -i /home/user/reads -o output -sdb output -c 0.8\n\n\n\n\n\n\nKeep around temporary files created during execution to take a look at afterwards.\n\npython Extractor.py -i /home/user/reads -o output -sdb output -k\n\n\n\n\n\n\nDon't generate sequences for plasmids found, for speedy analysis.\n\npython Extractor.py -i /home/user/reads -o output -sdb output -nc\n\n\n\n\n\n\nMandatory Arguments\n\n\n\n\n-o, --output_dir\n: The location for your output folder. Can be anything you want it to. Output folder will be created if it does not exist.\n\n\n-sdb, --sequence_db\n: The path to your sequence database. This database should be an uncompressed multi-fasta file. You can create your own custom database\nof plasmid sequences, or append any plasmid sequences you want to the supplied database.\n\n\n-i, --input_directory\n: The path to your input directory, which contains your paired-end reads to be analyzed. These reads can be uncompressed, or gzip/bzip2 compressed. It is assumed that forward\n reads contain 'R1' and reverse reads contain 'R2'. This assumption can be changed with the \n-fid\n and \n-rid\n options.\n\n\n\n\nOptional Arguments\n\n\n\n\n-t, --threads\n: Number of CPUs to run your analysis on. By default this is the number of cores on your machine. Every step of the pipeline except for consensus sequence generation parallelizes quite well, so it's recommended that this be left at the default unless you need to run other jobs at the same time.\n\n\n-k, --keep_tmpfiles\n: By default, a temporary directory is created in the output folder specified with \n-o\n for each sample and deleted once analysis is complete. Temporary files such as quality-trimmed reads and plasmid-only reads are kept here. Specifying this option will keep these temporary files instead of deleting them, in case you want to inspect intermediate files more closely. \n\n\n-c, --cutoff\n: The score cutoff for a plasmid to be considered present. Corresponds roughly to the percent identity between the generated plasmid and the reference plasmid. By default, set to 0.98 to only allow plasmids to be found that are quite similar. Lower values will generally return more plasmids, with less specificity. \n\n\n-r, --report\n: Name for report that will be created in \n--output_dir\n. Defaults to plasmidReport.csv, but can be changed to whatever you like.\n\n\n-fid, --forward_id\n: Identifier for forward reads. Defaults to \nR1\n, but if your forward reads use a different naming scheme like \n_1\n, specify \n-fid _1\n to have these recognized as forward reads.\n\n\n-rid, --reverse_id\n: Same as \n-fid\n, but for reverse reads.\n\n\n-nc, --no_consensus\n: Finding consensus sequences takes a fair chunk of time. If you want to skip this step and only identify the plasmids present in your sample, add this option. Adding this option means that any post-analysis of your plasmids that would usually take place (AMR detection, etc) will not occur.",
            "title": "Usage"
        },
        {
            "location": "/usage/#quickstart",
            "text": "The basic usage of Plasmid Extractor is fairly simple. As input, you will need to provide:   a folder containing paired-end reads that you think may have plasmids in them. It is assumed that forward reads contain 'R1' in their name and reverse reads contain 'R2' - see detailed usage for information on how to change this if your reads are named differently.   a plasmid database (included with the PlasmidExtractor distribution)   the path to a folder where you would like your output to be place (this folder will be created if it does not exist).   For example, in order to analyze the reads in the directory  /home/user/reads  and place the output into  output  using the default plasmid database, the command would be: python Extractor.py -i /home/user/reads -o output -sdb output  Within the output directory, you will find the following:   a CSV file called plasmidReport.csv, which shows the plasmids found for each sample, along with a score that shows (approximately) the percent identity to a reference plasmid  a folder for each sample, which contains a FASTA file for each plasmid found, a FASTA file with the plasmids concatenated, and the input reads with any plasmid reads discarded  if there was more than one sample, an image file showing a dendrogram of similarity of the total plasmid content of each sample, as well as a heatmap showing similarity  a log file for each sample showing the output from each step of the pipeline",
            "title": "Quickstart"
        },
        {
            "location": "/usage/#detailed-usage",
            "text": "The input parameters of Plasmid Extractor can be customized to your liking. Here are a few examples of different things that could be done:    Set identity cutoff to 0.8, to increase sensitivity at the cost of specificity. python Extractor.py -i /home/user/reads -o output -sdb output -c 0.8    Keep around temporary files created during execution to take a look at afterwards. python Extractor.py -i /home/user/reads -o output -sdb output -k    Don't generate sequences for plasmids found, for speedy analysis. python Extractor.py -i /home/user/reads -o output -sdb output -nc    Mandatory Arguments   -o, --output_dir : The location for your output folder. Can be anything you want it to. Output folder will be created if it does not exist.  -sdb, --sequence_db : The path to your sequence database. This database should be an uncompressed multi-fasta file. You can create your own custom database\nof plasmid sequences, or append any plasmid sequences you want to the supplied database.  -i, --input_directory : The path to your input directory, which contains your paired-end reads to be analyzed. These reads can be uncompressed, or gzip/bzip2 compressed. It is assumed that forward\n reads contain 'R1' and reverse reads contain 'R2'. This assumption can be changed with the  -fid  and  -rid  options.   Optional Arguments   -t, --threads : Number of CPUs to run your analysis on. By default this is the number of cores on your machine. Every step of the pipeline except for consensus sequence generation parallelizes quite well, so it's recommended that this be left at the default unless you need to run other jobs at the same time.  -k, --keep_tmpfiles : By default, a temporary directory is created in the output folder specified with  -o  for each sample and deleted once analysis is complete. Temporary files such as quality-trimmed reads and plasmid-only reads are kept here. Specifying this option will keep these temporary files instead of deleting them, in case you want to inspect intermediate files more closely.   -c, --cutoff : The score cutoff for a plasmid to be considered present. Corresponds roughly to the percent identity between the generated plasmid and the reference plasmid. By default, set to 0.98 to only allow plasmids to be found that are quite similar. Lower values will generally return more plasmids, with less specificity.   -r, --report : Name for report that will be created in  --output_dir . Defaults to plasmidReport.csv, but can be changed to whatever you like.  -fid, --forward_id : Identifier for forward reads. Defaults to  R1 , but if your forward reads use a different naming scheme like  _1 , specify  -fid _1  to have these recognized as forward reads.  -rid, --reverse_id : Same as  -fid , but for reverse reads.  -nc, --no_consensus : Finding consensus sequences takes a fair chunk of time. If you want to skip this step and only identify the plasmids present in your sample, add this option. Adding this option means that any post-analysis of your plasmids that would usually take place (AMR detection, etc) will not occur.",
            "title": "Detailed Usage"
        },
        {
            "location": "/FAQ/",
            "text": "",
            "title": "FAQ"
        }
    ]
}